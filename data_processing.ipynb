{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import requests\n",
    "import time \n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "import hashlib\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"/Users/eunkyungcha/GitHub/london_neighbourhood_recommendation/london_neighbourhood_recommendation/api\")\n",
    "from api_geocode import reverse_geocode\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811a0c8",
   "metadata": {},
   "source": [
    "# London Postcodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43aaec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/sjq4vmyj1tjf8k573fp7r6_40000gn/T/ipykernel_95585/2273394862.py:1: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_post = pd.read_csv(\"data/postcode_v0.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_post = pd.read_csv(\"data/postcode_v0.csv\")\n",
    "\n",
    "df_post.columns = df_post.columns.str.strip().str.lower().str.replace(\" \",\"_\")\n",
    "columns_to_keep = [\"postcode\", \"county\", \"district\", \"ward\", \"population\", \"households\",\"nearest_station\", \"police_force\", \"average_income\", \"property_type\", \"roads\"]\n",
    "df_post = df_post[columns_to_keep]\n",
    "\n",
    "df_post.to_csv(\"data/postcode_v1_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "300df624",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"postcode\",\"district\",\"ward\",\"nearest_station\"]\n",
    "df_post = df_post[columns_to_keep]\n",
    "df_post.to_csv(\"data/postcode_v2_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d484c3",
   "metadata": {},
   "source": [
    "# Housing Price in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12a2f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial cleaning\n",
    "# using the sale_estimate from 2024 analysis to reflect the realistic price \n",
    "df_house = pd.read_csv(\"data/house_v0.csv\")\n",
    "\n",
    "df_house.columns = df_house.columns.str.strip().str.lower().str.replace(\" \",\"_\")\n",
    "columns_to_keep = [\"postcode\",\"outcode\",\"latitude\",\"longitude\",\"bathrooms\",\"bedrooms\",\"floorareasqm\",\"livingrooms\",\"tenure\",\"propertytype\",\"saleestimate_currentprice\"]\n",
    "df_house = df_house[columns_to_keep]\n",
    "\n",
    "df_house.to_csv(\"data/house_v1_cleaned.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d7dc2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# property type category\n",
    "bungalow_types = [\"Bungalow Property\", \"Detached Bungalow\", \"End Terrace Bungalow\",\n",
    "    \"Mid Terrace Bungalow\", \"Semi-Detached Bungalow\", \"Terraced Bungalow\",\n",
    "    \"Terrace Property\", \"Semi-Detached Property\", \"Terraced\"]\n",
    "\n",
    "house_types = [\n",
    "    \"Detached House\", \"End Terrace House\", \"Semi-Detached House\",\n",
    "    \"Mid Terrace House\", \"End Terrace Property\", \"Mid Terrace Property\", \n",
    "    \"Detached Property\"\n",
    "]\n",
    "\n",
    "flat_types = [\"Converted Flat\", \"Flat/Maisonette\", \"Purpose Built Flat\"]\n",
    "\n",
    "# convert \n",
    "\n",
    "def convert_property_type(ptype):\n",
    "    if ptype in bungalow_types:\n",
    "        return \"Bungalow\"\n",
    "    elif ptype in house_types:\n",
    "        return \"House\"\n",
    "    elif ptype in flat_types:\n",
    "        return \"Flat\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "df_house[\"propertytype_converted\"] = df_house[\"propertytype\"].apply(convert_property_type)\n",
    "columns_to_drop = [\"propertytype\"]\n",
    "df_house = df_house.drop(columns = columns_to_drop)\n",
    "\n",
    "df_house.to_csv(\"data/house_v2_propertyType_converted.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4ff0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the postcode dataset to the house dataset - join on postcode \n",
    "# to get the area name in each postcode area \n",
    "\n",
    "df_house_merged = df_house.merge(df_post, on = \"postcode\", how = \"left\")\n",
    "\n",
    "column_order = [\n",
    "    \"postcode\", \"outcode\", \"district\", \"ward\", \"livingrooms\",\n",
    "    \"bedrooms\", \"bathrooms\", \"floorareasqm\", \"tenure\", \"propertytype_converted\",\n",
    "    \"saleestimate_currentprice\", \"nearest_station\",\"latitude\",\"longitude\"\n",
    "]\n",
    "\n",
    "df_house_merged = df_house_merged[column_order]\n",
    "\n",
    "df_house_merged.to_csv(\"data/house_v3_mergedWithPost.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8895c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by outcode + ward \n",
    "\n",
    "group_cols = [\"outcode\",\"ward\",\"livingrooms\",\"bedrooms\",\"bathrooms\",\"tenure\",\"propertytype_converted\"]\n",
    "agg_col = \"saleestimate_currentprice\"\n",
    "\n",
    "df_house_grouped  = df_house_merged.dropna(subset = group_cols + [agg_col])\n",
    "\n",
    "df_house_agg = (df_house_grouped.groupby(group_cols).agg(\n",
    "    median_price=(agg_col, \"median\"),\n",
    "    district = (\"district\",\"first\"),\n",
    "    nearest_station = (\"nearest_station\",\"first\"))).reset_index() \n",
    "\n",
    "column_order = [\n",
    "    \"outcode\",\"ward\",\"district\",\"livingrooms\",\"bedrooms\",\"bathrooms\",\"tenure\",\"propertytype_converted\",\"median_price\",\"nearest_station\"\n",
    "]\n",
    "\n",
    "df_house_agg = df_house_agg[column_order]\n",
    "df_house_agg = df_house_agg.dropna(subset=[\"outcode\", \"ward\"])\n",
    "\n",
    "df_house_agg.to_csv(\"data/house_v4_agg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f97fa0",
   "metadata": {},
   "source": [
    "# Crime Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3b444f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2024-01-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-01-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-02-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-02-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-03-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-03-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-04-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-04-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-05-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-05-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-06-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-06-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-07-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-07-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-08-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-08-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-09-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-09-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-10-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-10-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-11-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-11-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-12-city-of-london-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "Loading 2024-12-metropolitan-street.csv...\n",
      "Columns: ['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type', 'Last outcome category', 'Context']\n",
      "combined shape: (1149321, 12)\n",
      "                                            Crime ID    Month  \\\n",
      "0  e7b720d0e1302d2d06db7b28b29132eb194864d44d7921...  2024-01   \n",
      "1  e60a5ac62a80e866453254474137c3206417422c62f0c0...  2024-01   \n",
      "2  986f618142ec52b7f254e4b0549da2f17ceeb0e130db6c...  2024-01   \n",
      "3  05dc27a88748356f6d59b0bd1389710ebfb42b37e565af...  2024-01   \n",
      "4  373d78e2ccec5d05a547cd4bee19045a9e050042a0e6e7...  2024-01   \n",
      "\n",
      "             Reported by           Falls within  Longitude   Latitude  \\\n",
      "0  City of London Police  City of London Police  -0.106220  51.518275   \n",
      "1  City of London Police  City of London Police  -0.107682  51.517786   \n",
      "2  City of London Police  City of London Police  -0.111596  51.518281   \n",
      "3  City of London Police  City of London Police  -0.111596  51.518281   \n",
      "4  City of London Police  City of London Police  -0.112096  51.515942   \n",
      "\n",
      "                   Location  LSOA code    LSOA name             Crime type  \\\n",
      "0           On or near B500  E01000916  Camden 027B  Theft from the person   \n",
      "1           On or near B521  E01000917  Camden 027C            Other theft   \n",
      "2  On or near Chancery Lane  E01000914  Camden 028B            Other theft   \n",
      "3  On or near Chancery Lane  E01000914  Camden 028B  Theft from the person   \n",
      "4      On or near Nightclub  E01000914  Camden 028B  Theft from the person   \n",
      "\n",
      "                           Last outcome category  Context  \n",
      "0  Investigation complete; no suspect identified      NaN  \n",
      "1  Investigation complete; no suspect identified      NaN  \n",
      "2  Investigation complete; no suspect identified      NaN  \n",
      "3                      Status update unavailable      NaN  \n",
      "4  Investigation complete; no suspect identified      NaN  \n"
     ]
    }
   ],
   "source": [
    "folder_path = \"data/2024_crime_report\"\n",
    "all_crime_data = []\n",
    "\n",
    "for month_folder in sorted(os.listdir(folder_path)):\n",
    "    month_folder_path = os.path.join(folder_path, month_folder)\n",
    "    if os.path.isdir(month_folder_path):\n",
    "        monthly_data = []\n",
    "        \n",
    "        for filename in sorted(os.listdir(month_folder_path)):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                file_path = os.path.join(month_folder_path, filename)\n",
    "                print(f\"Loading {filename}...\")\n",
    "                df_crime = pd.read_csv(file_path)\n",
    "                print(\"Columns:\", list(df_crime.columns))\n",
    "                monthly_data.append(df_crime)\n",
    "        \n",
    "        if monthly_data:\n",
    "            first_columns = monthly_data[0].columns\n",
    "            for i, df_crime in enumerate(monthly_data):\n",
    "                if not df_crime.columns.equals(first_columns):\n",
    "                    print(f\"Columns do not match in {month_folder}, file {i}: {df_crime.columns}\")\n",
    "            df_month_combined = pd.concat(monthly_data, ignore_index = True)\n",
    "            all_crime_data.append(df_month_combined)\n",
    "                    \n",
    "\n",
    "if not all_crime_data:\n",
    "    print(\"csv file not found.\")\n",
    "else:\n",
    "    first_columns = all_crime_data[0].columns\n",
    "    for i, df_crime in enumerate(all_crime_data):\n",
    "        if not df_crime.columns.equals(first_columns):\n",
    "            print(f\"Columns do not match in file {i}: {df_crime.columns}\")\n",
    "\n",
    "df_crime = pd.concat(all_crime_data, ignore_index=True)\n",
    "\n",
    "print(\"combined shape:\", df_crime.shape)\n",
    "print(df_crime.head())\n",
    "\n",
    "df_crime.to_csv(\"data/crime_v1_combined.csv\", index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4765d491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1147685 entries, 0 to 1149320\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count    Dtype         \n",
      "---  ------       --------------    -----         \n",
      " 0   month        1147685 non-null  datetime64[ns]\n",
      " 1   reported_by  1147685 non-null  object        \n",
      " 2   longitude    1147685 non-null  float64       \n",
      " 3   latitude     1147685 non-null  float64       \n",
      " 4   location     1147685 non-null  object        \n",
      " 5   crime_type   1147685 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(3)\n",
      "memory usage: 61.3+ MB\n",
      "None\n",
      "       month            reported_by  longitude   latitude  \\\n",
      "0 2024-01-01  City of London Police  -0.106220  51.518275   \n",
      "1 2024-01-01  City of London Police  -0.107682  51.517786   \n",
      "2 2024-01-01  City of London Police  -0.111596  51.518281   \n",
      "3 2024-01-01  City of London Police  -0.111596  51.518281   \n",
      "4 2024-01-01  City of London Police  -0.112096  51.515942   \n",
      "\n",
      "                   location             crime_type  \n",
      "0           On or near B500  Theft from the person  \n",
      "1           On or near B521            Other theft  \n",
      "2  On or near Chancery Lane            Other theft  \n",
      "3  On or near Chancery Lane  Theft from the person  \n",
      "4      On or near Nightclub  Theft from the person  \n"
     ]
    }
   ],
   "source": [
    "df_crime.columns = df_crime.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"month\", \"reported_by\", \"longitude\", \"latitude\", \n",
    "    \"location\", \"crime_type\"\n",
    "]\n",
    "\n",
    "df_crime = df_crime[columns_to_keep]\n",
    "\n",
    "df_crime = df_crime.dropna(subset = [\"longitude\",\"latitude\"])\n",
    "\n",
    "df_crime = df_crime[~(df_crime[\"location\"].str.strip() == \"\")]\n",
    "df_crime = df_crime[~(df_crime[\"crime_type\"].str.strip() == \"\")]\n",
    "\n",
    "df_crime[\"month\"] = pd.to_datetime(df_crime[\"month\"])\n",
    "\n",
    "print(df_crime.info())\n",
    "print(df_crime.head())\n",
    "\n",
    "df_crime.to_csv(\"data/crime_v2_cleaned.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624e3784",
   "metadata": {},
   "source": [
    "### longitude & latitude to postcodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "77bfa179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique coordinates to lookup: 60948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 277/610 [07:28<22:36,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during batch request: HTTPSConnectionPool(host='api.postcodes.io', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [16:15<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset with postcodes to data/crime_v3_with_postcode.csv\n"
     ]
    }
   ],
   "source": [
    "# google geocoding API takes a very long time to process, so we will use postcodes.io API instead \n",
    "\n",
    "def fetch_postcodes_postcodesio_batch(coords_batch):\n",
    "    url = \"https://api.postcodes.io/postcodes\"\n",
    "    payload = {\"geolocations\": [{\"longitude\": lng, \"latitude\": lat} for lat, lng in coords_batch]}\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=10)\n",
    "        data = response.json()\n",
    "        results = data.get(\"result\", [])\n",
    "        postcodes = []\n",
    "        for item in results:\n",
    "            if item and item.get(\"result\"):\n",
    "                postcode = item[\"result\"][0].get(\"postcode\")\n",
    "                postcodes.append(postcode)\n",
    "            else:\n",
    "                postcodes.append(None)\n",
    "        return postcodes\n",
    "    except Exception as e:\n",
    "        print(f\"Error during batch request: {e}\")\n",
    "        return [None] * len(coords_batch)\n",
    "\n",
    "def add_postcode_using_postcodesio(df_crime, cache_pkl=\"coord_to_postcode.pkl\"):\n",
    "    lng_col = \"longitude\" if \"longitude\" in df_crime.columns else \"longtitude\"\n",
    "    df_crime[\"lat_rounded\"] = df_crime[\"latitude\"].round(5)\n",
    "    df_crime[\"lng_rounded\"] = df_crime[lng_col].round(5)\n",
    "\n",
    "    # unique coordinate set\n",
    "    unique_coords = df_crime[[\"lat_rounded\", \"lng_rounded\"]].drop_duplicates()\n",
    "    coord_list = list(unique_coords.itertuples(index=False, name=None))\n",
    "\n",
    "    print(f\"Total unique coordinates to lookup: {len(coord_list)}\")\n",
    "\n",
    "    coord_to_postcode = {}\n",
    "    batch_size = 100\n",
    "\n",
    "    for i in tqdm(range(0, len(coord_list), batch_size)):\n",
    "        batch = coord_list[i:i+batch_size]\n",
    "        postcodes = fetch_postcodes_postcodesio_batch(batch)\n",
    "        for coord, postcode in zip(batch, postcodes):\n",
    "            coord_to_postcode[coord] = postcode\n",
    "        time.sleep(0.05)  # setting the delay to 50ms to avoid hitting the rate limit\n",
    "\n",
    "    # Saving the lookup dictionary for future reuse just in case\n",
    "    with open(cache_pkl, \"wb\") as f:\n",
    "        pickle.dump(coord_to_postcode, f)\n",
    "\n",
    "    # Map using vectorised .map for speed\n",
    "    df_crime[\"coord_key\"] = list(zip(df_crime[\"lat_rounded\"], df_crime[\"lng_rounded\"]))\n",
    "    df_crime[\"postcode\"] = df_crime[\"coord_key\"].map(coord_to_postcode)\n",
    "\n",
    "    # Clean up\n",
    "    df_crime.drop(columns=[\"lat_rounded\", \"lng_rounded\", \"coord_key\"], inplace=True)\n",
    "\n",
    "    return df_crime\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_crime = pd.read_csv(\"data/crime_v2_cleaned.csv\")\n",
    "\n",
    "    # add postcodes to the dataset\n",
    "    df_crime = add_postcode_using_postcodesio(df_crime, cache_pkl=\"data/coord_to_postcode.pkl\")\n",
    "\n",
    "    df_crime.to_csv(\"data/crime_v3_with_postcode.csv\", index=False)\n",
    "    print(\"Saved dataset with postcodes to data/crime_v3_with_postcode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14355c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the postcode dataset to the crime dataset \n",
    "# to get the area name in each postcode  \n",
    "df_crime = pd.read_csv(\"data/crime_v3_with_postcode.csv\")\n",
    "\n",
    "df_crime_merged = df_crime.merge(df_post, on = [\"postcode\"], how = \"left\")\n",
    "\n",
    "df_crime_merged = df_crime_merged.drop(columns = [\"reported_by\",\"longitude\",\"latitude\",\"location\",\"nearest_station\"])\n",
    "\n",
    "# add outcode\n",
    "df_crime_merged[\"outcode\"] = df_crime_merged[\"postcode\"].str.extract(r\"^([A-Z]{1,2}\\d{1,2}[A-Z]?)\")\n",
    "\n",
    "column_order = [\n",
    "    \"month\",\"postcode\",\"outcode\",\"ward\",\"district\",\"crime_type\"\n",
    "]\n",
    "df_crime_merged = df_crime_merged[column_order]\n",
    "\n",
    "# drop all rows with non-London postcode\n",
    "df_crime_merged = df_crime_merged.dropna(subset=[\"outcode\",\"ward\"])\n",
    "\n",
    "df_crime_merged.to_csv(\"data/crime_v4_mergedWithPost.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e3dde",
   "metadata": {},
   "source": [
    "# Population \n",
    "for crime rate level categorisation & crime type count per outcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91eab3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/sjq4vmyj1tjf8k573fp7r6_40000gn/T/ipykernel_95585/4053501997.py:2: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pop = pd.read_csv(\"data/postcode_v0.csv\")\n"
     ]
    }
   ],
   "source": [
    "# population dataset processing\n",
    "df_pop = pd.read_csv(\"data/postcode_v0.csv\")\n",
    "df_pop.columns = df_pop.columns.str.strip().str.lower().str.replace(\" \",\"_\")\n",
    "\n",
    "columns_to_keep = [\"postcode\",\"ward\",\"population\"]\n",
    "df_pop = df_pop[columns_to_keep]\n",
    "\n",
    "# add outcode \n",
    "df_pop[\"outcode\"] = df_pop[\"postcode\"].str.extract(r\"^([A-Z]{1,2}\\d{1,2}[A-Z]?)\")\n",
    "# remove postcode\n",
    "df_pop = df_pop.drop(columns = [\"postcode\"])\n",
    "\n",
    "column_order = [\"outcode\",\"ward\",\"population\"]\n",
    "df_pop = df_pop[column_order]\n",
    "\n",
    "df_pop.to_csv(\"data/population_v1_extractedFromPost.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e9574ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_grouped = df_pop.groupby([\"outcode\",\"ward\"], as_index = False)[\"population\"].sum()\n",
    "df_pop_grouped.rename(columns={\"population\":\"total_population\"}, inplace = True)\n",
    "\n",
    "df_pop_grouped.to_csv(\"data/population_v2_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77cc8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the crime report dataset using outcode\n",
    "# crime rate per outcode & ward\n",
    "df_crime = pd.read_csv(\"data/crime_v4_mergedWithPost.csv\")\n",
    "df_pop = pd.read_csv(\"data/population_v2_agg.csv\")\n",
    "\n",
    "# crime count per outcode & ward\n",
    "df_crime_counts = df_crime.groupby([\"outcode\",\"ward\"]).size().reset_index(name=\"crime_counts\")\n",
    "\n",
    "# merge with population data on outcode, then calculate the crime rate per 1000 ppl \n",
    "df_crime_level = df_crime_counts.merge(df_pop, on=[\"outcode\",\"ward\"], how=\"left\")\n",
    "df_crime_level[\"crime_rate_per_1000\"] = (df_crime_level[\"crime_counts\"]/df_crime_level[\"total_population\"]) * 1000 \n",
    "\n",
    "# categorise crime rate level \n",
    "def categorise_crime(rate):\n",
    "    if pd.isna(rate):\n",
    "        return \"No info\"\n",
    "    elif rate < 140:\n",
    "        return \"Low crime\"\n",
    "    elif rate <= 225:\n",
    "        return \"Medium crime\"\n",
    "    else:\n",
    "        return \"High crime\"\n",
    "    \n",
    "\n",
    "df_crime_level[\"crime_level\"] = df_crime_level[\"crime_rate_per_1000\"].apply(categorise_crime)\n",
    "\n",
    "\n",
    "# top 3 crimes per outcode\n",
    "df_top_crimes = (\n",
    "    df_crime.groupby([\"outcode\",\"ward\", \"crime_type\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "df_top3_crimes = (\n",
    "    df_top_crimes.sort_values([\"outcode\",\"ward\",\"count\"], ascending=[True, True, False])\n",
    "    .groupby([\"outcode\",\"ward\"])\n",
    "    .head(3)\n",
    ")\n",
    "\n",
    "df_top3_crimes[\"rank\"] = df_top3_crimes.groupby([\"outcode\",\"ward\"]).cumcount()+1\n",
    "df_crime_rank = df_top3_crimes.pivot(index=[\"outcode\",\"ward\"],columns=\"rank\", values=\"crime_type\").reset_index()\n",
    "df_crime_rank.columns = [\"outcode\",\"ward\",\"crime_1\",\"crime_2\",\"crime_3\"]\n",
    "\n",
    "df_crime_combined = df_crime_merged.merge(df_crime_level, on=[\"outcode\",\"ward\"], how=\"left\")\n",
    "df_crime_combined = df_crime_combined.merge(df_crime_rank, on=[\"outcode\",\"ward\"], how=\"left\")\n",
    "\n",
    "\n",
    "df_crime_combined.to_csv(\"data/crime_v5_combined_stats.csv\", index=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f6058fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_combined = pd.read_csv(\"data/crime_v5_combined_stats.csv\")\n",
    "\n",
    "columns_to_keep = [\"outcode\",\"district\",\"ward\",\"crime_level\",\"crime_1\",\"crime_2\",\"crime_3\"]\n",
    "df_crime_combined = df_crime_combined[columns_to_keep]\n",
    "\n",
    "df_crime_combined = df_crime_combined.drop_duplicates(subset=[\"outcode\",\"ward\"])\n",
    "df_crime_combined = df_crime_combined.dropna(subset=[\"outcode\", \"ward\"])\n",
    "\n",
    "df_crime_combined.to_csv(\"data/crime_v6_combined_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9dadfe",
   "metadata": {},
   "source": [
    "# Public School Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9831ee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['London' 'South East' 'North East, Yorkshire and the Humber'\n",
      " 'West Midlands' 'North West' 'South West' 'East of England'\n",
      " 'East Midlands']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/sjq4vmyj1tjf8k573fp7r6_40000gn/T/ipykernel_95585/3392353320.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_school = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "df_school = pd.read_csv(\n",
    "    \"data/school_v0.csv\",\n",
    "    encoding=\"ISO-8859-1\"\n",
    ")\n",
    "\n",
    "df_school.columns = df_school.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "columns_to_keep = [\"school_name\",\"ofsted_phase\",\"type_of_education\",\"ungraded_inspection_overall_outcome\",\"sixth_form\",\"designated_religious_character\",\"ofsted_region\",\"local_authority\",\"postcode\",\"total_number_of_pupils\",\"statutory_lowest_age\",\"statutory_highest_age\"]\n",
    "df_school = df_school[columns_to_keep]\n",
    "\n",
    "print(df_school[\"ofsted_region\"].unique()) # unique values of each column\n",
    "df_school = df_school[df_school[\"ofsted_region\"] == \"London\"] # only include London\n",
    "\n",
    "df_school = df_school.fillna(\"No info\")\n",
    "\n",
    "allowed_phrases = [\"School remains Good\", \"School remains Outstanding\", \"No information\"]\n",
    "df_school = df_school[df_school[\"ungraded_inspection_overall_outcome\"].isin(allowed_phrases)].copy()\n",
    "\n",
    "# convert\n",
    "df_school[\"ungraded_inspection_overall_outcome\"] = df_school[\"ungraded_inspection_overall_outcome\"].replace({\n",
    "    \"School remains Good\": \"Good\",\n",
    "    \"School remains Outstanding\": \"Outstanding\",\n",
    "    \"No information\": \"No information\"\n",
    "})\n",
    "\n",
    "df_school.to_csv(\"data/school_v1_cleaned.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b55de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "df_post = pd.read_csv(\"data/postcode_v2_cleaned.csv\")\n",
    "df_school_merged = df_school.merge(df_post, on = \"postcode\", how = \"left\")\n",
    "\n",
    "# add outcode column and remove postcode column\n",
    "df_school_merged[\"outcode\"] = df_school_merged[\"postcode\"].str.extract(r\"^([A-Z]{1,2}\\d{1,2}[A-Z]?)\")\n",
    "df_school_merged = df_school_merged.drop(columns=[\"postcode\",\"nearest_station\",\"ofsted_region\",\"local_authority\"])\n",
    "\n",
    "# reorder the columns\n",
    "column_order = [\"outcode\",\"ward\",\"district\",\"school_name\",\"ofsted_phase\",\"type_of_education\",\"ungraded_inspection_overall_outcome\",\"sixth_form\",\"designated_religious_character\",\"total_number_of_pupils\",\"statutory_lowest_age\",\"statutory_highest_age\"]\n",
    "df_school_merged = df_school_merged[column_order]\n",
    "\n",
    "\n",
    "df_school_merged.to_csv(\"data/school_v2_mergedWithPost.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aec6ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['outcode', 'ward', 'district', 'school_name', 'ofsted_phase',\n",
      "       'type_of_education', 'ungraded_inspection_overall_outcome',\n",
      "       'sixth_form', 'designated_religious_character',\n",
      "       'total_number_of_pupils', 'statutory_lowest_age',\n",
      "       'statutory_highest_age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_school_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76aafefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group school data by good or outstanding schools - per outcode & ward\n",
    "\n",
    "good_schools = df_school_merged[df_school_merged[\"ungraded_inspection_overall_outcome\"] == \"Good\"]\n",
    "outstanding_schools = df_school_merged[df_school_merged[\"ungraded_inspection_overall_outcome\"] == \"Outstanding\"]\n",
    "\n",
    "summary_good = (\n",
    "    good_schools.groupby([\"outcode\",\"ward\"]).agg(\n",
    "    num_good = (\"school_name\", \"count\"),\n",
    "    schools_good = (\"school_name\", lambda names: \"; \".join(names)))\n",
    ".reset_index()\n",
    ")\n",
    "\n",
    "summary_outstanding = (\n",
    "    outstanding_schools.groupby([\"outcode\",\"ward\"]).agg(\n",
    "        num_outstanding = (\"school_name\",\"count\"),\n",
    "        schools_outstanding = (\"school_name\", lambda names: \"; \".join(names)))\n",
    ".reset_index()\n",
    ")\n",
    " # merging \n",
    "school_summary = pd.merge(summary_good, summary_outstanding, on=[\"outcode\",\"ward\"], how=\"outer\")\n",
    "\n",
    "# filling empty cells \n",
    "school_summary[\"num_good\"] = school_summary[\"num_good\"].fillna(0).astype(int)\n",
    "school_summary[\"num_outstanding\"] = school_summary[\"num_outstanding\"].fillna(0).astype(int)\n",
    "school_summary[\"schools_good\"] = school_summary[\"schools_good\"].fillna(\"No info\")\n",
    "school_summary[\"schools_outstanding\"] = school_summary[\"schools_outstanding\"].fillna(\"No info\")\n",
    "\n",
    "school_summary = school_summary.dropna(subset=[\"outcode\", \"ward\"])\n",
    "\n",
    "school_summary.to_csv(\"data/school_v3_agg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c161a79d",
   "metadata": {},
   "source": [
    "# Combine all dataset on outcode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11d4867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.read_csv(\"data/crime_v6_combined_cleaned.csv\")\n",
    "df_school = pd.read_csv(\"data/school_v3_agg.csv\")\n",
    "df_house = pd.read_csv(\"data/house_v4_agg.csv\")\n",
    "\n",
    "df_final = df_house.merge(df_crime, on = [\"outcode\",\"ward\"], how = \"left\")\n",
    "df_final = df_final.merge(df_school, on = [\"outcode\", \"ward\"], how = \"left\")\n",
    "\n",
    "# avoid generating multiple district columns\n",
    "if \"district_x\" in df_final.columns and \"district_y\" in df_final.columns:\n",
    "    df_final = df_final.rename(columns = {\"district_x\":\"district\"})\n",
    "    df_final = df_final.drop(columns = [\"district_y\"], errors = \"ignore\")\n",
    "    \n",
    "# drop index columns \n",
    "unnamed_cols = [col for col in df_final.columns if col.startswith(\"Unnamed\")]\n",
    "df_final = df_final.drop(columns = unnamed_cols)\n",
    "\n",
    "# fill empty values \n",
    "df_final[\"num_good\"] = df_final[\"num_good\"].fillna(0).astype(int)\n",
    "df_final[\"num_outstanding\"] = df_final[\"num_outstanding\"].fillna(0).astype(int)\n",
    "df_final[\"schools_good\"] = df_final[\"schools_good\"].fillna(\"No info\")\n",
    "df_final[\"schools_outstanding\"] = df_final[\"schools_outstanding\"].fillna(\"No info\")\n",
    "\n",
    "\n",
    "\n",
    "df_final.to_csv(\"final_data/final_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfa29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done...\n",
      "25 done...\n",
      "50 done...\n",
      "75 done...\n",
      "100 done...\n",
      "125 done...\n",
      "150 done...\n",
      "175 done...\n",
      "200 done...\n",
      "225 done...\n",
      "250 done...\n",
      "275 done...\n",
      "300 done...\n",
      "325 done...\n",
      "350 done...\n",
      "375 done...\n",
      "400 done...\n",
      "425 done...\n",
      "450 done...\n",
      "475 done...\n",
      "500 done...\n",
      "525 done...\n",
      "550 done...\n",
      "575 done...\n",
      "600 done...\n",
      "625 done...\n",
      "650 done...\n",
      "675 done...\n",
      "700 done...\n",
      "725 done...\n",
      "750 done...\n",
      "775 done...\n",
      "800 done...\n",
      "825 done...\n",
      "850 done...\n",
      "875 done...\n"
     ]
    }
   ],
   "source": [
    "# replace the coordinates according to the area name and outcode\n",
    "\n",
    "df_lat_lng = pd.read_csv(\"final_data/final_v1.csv\")\n",
    "\n",
    "df_lat_lng[\"query\"] = df_lat_lng[\"ward\"] + \", \" + df_lat_lng[\"outcode\"] + \", London, UK\"\n",
    "unique_queries = df_lat_lng[\"query\"].dropna().unique()\n",
    "\n",
    "def geocode_address(address, api_key):\n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    params = {\n",
    "        \"address\": address,\n",
    "        \"key\": api_key\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    if data[\"status\"] == \"OK\":\n",
    "        location = data[\"results\"][0][\"geometry\"][\"location\"]\n",
    "        return location[\"lat\"], location[\"lng\"]\n",
    "    else:\n",
    "        print(f\"Failed for {address}: {data.get('status')}\")\n",
    "        return None, None\n",
    "\n",
    "# get latitude and longitude for each unique query\n",
    "results = []\n",
    "for i, query in enumerate(unique_queries):\n",
    "    lat, lng = geocode_address(query, API_KEY)\n",
    "    results.append({\n",
    "        \"query\": query,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lng\n",
    "    })\n",
    "    time.sleep(0.1)\n",
    "    if i % 25 == 0:\n",
    "        print(f\"{i} done...\")\n",
    "\n",
    "# convert to dataframe\n",
    "df_coords = pd.DataFrame(results)\n",
    "\n",
    "# merge back with original dataset \n",
    "df_combined = df_lat_lng.merge(df_coords, on=\"query\", how=\"left\")\n",
    "\n",
    "# replace the old data with the new coordinates\n",
    "df_combined = df_combined.drop(columns=[\"latitude_x\", \"longitude_x\"], errors=\"ignore\")\n",
    "df_combined = df_combined.rename(columns={\"latitude_y\": \"latitude\", \"longitude_y\": \"longitude\"})\n",
    "\n",
    "\n",
    "df_combined.to_csv(\"final_data/final_v2_latlng.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "57d6992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv(\"final_data/final_v2_latlng.csv\")\n",
    "df_combined = df_combined.drop(columns = [\"Unnamed: 0\",\"query\"])\n",
    "\n",
    "# numeric and string columns\n",
    "numeric_columns = [\n",
    "  \"livingrooms\",\n",
    "  \"bedrooms\",\n",
    "  \"bathrooms\",\n",
    "  \"median_price\",\n",
    "  \"num_good\",\n",
    "  \"num_outstanding\",\n",
    "  \"latitude\",\n",
    "  \"longitude\"\n",
    "]\n",
    "\n",
    "string_columns = [\n",
    "    \"outcode\",\n",
    "    \"ward\",\n",
    "    \"district\",\n",
    "    \"tenure\",\n",
    "    \"propertytype_converted\",\n",
    "    \"nearest_station\",\n",
    "    \"crime_level\",\n",
    "    \"crime_1\",\n",
    "    \"crime_2\",\n",
    "    \"crime_3\",\n",
    "    \"schools_good\",\n",
    "    \"schools_outstanding\"\n",
    "]\n",
    "\n",
    "\n",
    "for col in numeric_columns:\n",
    "    df_combined[col] = pd.to_numeric(df_combined[col], errors=\"coerce\")  \n",
    "\n",
    "for col in string_columns:\n",
    "    df_combined[col] = df_combined[col].replace([\"\", \" \", None, np.nan], \"No info\")\n",
    "    \n",
    "\n",
    "df_combined.to_csv(\"final_data/final_v3_datatype.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0dd5bcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d48b4a3d-a4ba-4fe0-bcfc-892aa3ba3a97",
       "rows": [
        [
         "outcode",
         "0"
        ],
        [
         "ward",
         "0"
        ],
        [
         "district",
         "0"
        ],
        [
         "livingrooms",
         "0"
        ],
        [
         "bedrooms",
         "0"
        ],
        [
         "bathrooms",
         "0"
        ],
        [
         "tenure",
         "0"
        ],
        [
         "propertytype_converted",
         "0"
        ],
        [
         "median_price",
         "0"
        ],
        [
         "nearest_station",
         "0"
        ],
        [
         "crime_level",
         "0"
        ],
        [
         "crime_1",
         "0"
        ],
        [
         "crime_2",
         "0"
        ],
        [
         "crime_3",
         "0"
        ],
        [
         "num_good",
         "0"
        ],
        [
         "schools_good",
         "0"
        ],
        [
         "num_outstanding",
         "0"
        ],
        [
         "schools_outstanding",
         "0"
        ],
        [
         "latitude",
         "0"
        ],
        [
         "longitude",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 20
       }
      },
      "text/plain": [
       "outcode                   0\n",
       "ward                      0\n",
       "district                  0\n",
       "livingrooms               0\n",
       "bedrooms                  0\n",
       "bathrooms                 0\n",
       "tenure                    0\n",
       "propertytype_converted    0\n",
       "median_price              0\n",
       "nearest_station           0\n",
       "crime_level               0\n",
       "crime_1                   0\n",
       "crime_2                   0\n",
       "crime_3                   0\n",
       "num_good                  0\n",
       "schools_good              0\n",
       "num_outstanding           0\n",
       "schools_outstanding       0\n",
       "latitude                  0\n",
       "longitude                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266edf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
